# TRAINING-CONFIDENCE-CALIBRATED-CLASSIFIERS-FOR-DETECTING-OUT-OF-DISTRIBUTION-SAMPLES
A PyTorch implementation of the method proposed in the paper: https://arxiv.org/abs/1711.09325 .

Algorithm 1 from the paper is implemented together with code to train and evaluate the prediction accuracy as well as the detection accuracy when the method is trained with CIFAR10 as "in-distribution" and tested with SVHN as "out-of-distribution". 

There are logs from two test runs runnings for 3500 gradient steps, one when only the cross entropy is used to train the classifier and the other with the, in the paper proposed, joint confidence loss. In the one using joint confidence loss, images generated by the GAN can also be seen. 

Train the VGG13 classifier with Joint Confidence Loss (using DCGAN based GAN): ``` python3 main.py  ``` .
This trains the networks using algorithm 1 from the paper and finally prints the results which in the paper can be seen in the bottom left corner of figure 4. That is, the Detection accuracy for the Joint Confidence Loss (blue bar) when CIFAR-10 is used as the In-distribution data and SVHN as the Out-of-Distribution data.  
Training progress can be tracked be loading the logs saved in the directory specified by ``` --save_model ``` using TensorBoard.

Train the VGG13 classifier with only Cross Entropy Loss (no GAN): ``` python3 main.py --use_confidence_loss 0 ``` .
This prints the results which in the paper can be seen in the bottom left corner of figure 4. That is, the Detection accuracy for the Cross entropy loss (red bar) when CIFAR-10 is used as the In-distribution data and SVHN as the Out-of-Distribution data.

Various hyperparameters can be set prior to training, to see which, run: ``` python3 main.py -h ``` . 
Default values are set to parameter values mentioned in the paper, a thorough search has not been done so these might not be the optimal ones.
